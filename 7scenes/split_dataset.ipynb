{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train and test label text for chess ...\n",
      "Save ../data/7Scenes/chess/dataset_train.txt, training frame number: 4000\n",
      "Save ../data/7Scenes/chess/dataset_test.txt, testing frame number: 2000\n",
      "\n",
      "Generating train and test label text for heads ...\n",
      "Save ../data/7Scenes/heads/dataset_train.txt, training frame number: 1000\n",
      "Save ../data/7Scenes/heads/dataset_test.txt, testing frame number: 1000\n",
      "\n",
      "Generating train and test label text for fire ...\n",
      "Save ../data/7Scenes/fire/dataset_train.txt, training frame number: 2000\n",
      "Save ../data/7Scenes/fire/dataset_test.txt, testing frame number: 2000\n",
      "\n",
      "Generating train and test label text for office ...\n",
      "Save ../data/7Scenes/office/dataset_train.txt, training frame number: 6000\n",
      "Save ../data/7Scenes/office/dataset_test.txt, testing frame number: 4000\n",
      "\n",
      "Generating train and test label text for pumpkin ...\n",
      "Save ../data/7Scenes/pumpkin/dataset_train.txt, training frame number: 4000\n",
      "Save ../data/7Scenes/pumpkin/dataset_test.txt, testing frame number: 2000\n",
      "\n",
      "Generating train and test label text for redkitchen ...\n",
      "Save ../data/7Scenes/redkitchen/dataset_train.txt, training frame number: 7000\n",
      "Save ../data/7Scenes/redkitchen/dataset_test.txt, testing frame number: 5000\n",
      "\n",
      "Generating train and test label text for stairs ...\n",
      "Save ../data/7Scenes/stairs/dataset_train.txt, training frame number: 2000\n",
      "Save ../data/7Scenes/stairs/dataset_test.txt, testing frame number: 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "from transforms3d.quaternions import mat2quat\n",
    "\n",
    "origin_dir = '../data/7Scenes/'\n",
    "datasets = ['chess', 'heads', 'fire', 'office', 'pumpkin', 'redkitchen', 'stairs']\n",
    "target_dir = '../data/7Scenes_256/'\n",
    "\n",
    "# Dataset sequence split, key: dataset, value: (train seq, test seq)\n",
    "split = {'chess' : (['01', '02', '04', '06'],['03', '05']),\n",
    "         'heads' : (['02'],['01']),  # Reversed \n",
    "         'fire' : (['01', '02'], ['03', '04']), \n",
    "         'office' : (['01', '03', '04', '05', '08', '10'],['02', '06', '07', '09']), \n",
    "         'pumpkin' : (['02', '03', '06', '08'],['01', '07']),\n",
    "         'redkitchen' : (['01', '02', '05', '07', '08', '11', '13'],['03', '04', '06', '12', '14']), \n",
    "         'stairs' : (['02', '03', '05', '06'],['01', '04'])\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "Format explanation:\n",
    "In dataset/frame*.pose.txt, pose=[R|t] is camera-to-world which fulfils X_world = R*X_cam + t\n",
    "In our formulation we want pose_=[R_|c_] which fulfils X_cam = R_*(X_world - c_)\n",
    "Therefore, each line in the *.new.txt follows: imframe x y z w p q r,\n",
    "Notice xyz is c_ with c_=t and wpqr is mat2quat(R_) with R_ = R.T, where [R|t] are the pose in the original frame*.pose.txt\n",
    "\"\"\"\n",
    "train_txt = 'dataset_train.txt'\n",
    "test_txt = 'dataset_test.txt'\n",
    "for dataset in datasets:\n",
    "    print('Generating train and test label text for {} ...'.format(dataset))\n",
    "    train_num = 0\n",
    "    test_num = 0\n",
    "    train_seqs = split[dataset][0]\n",
    "    with open(os.path.join(target_dir, dataset, train_txt), 'w') as ftrain:\n",
    "        ftrain.write('7Scenes {} Dataset -- Train Split\\n'.format(dataset))\n",
    "        ftrain.write('ImageFile, Camera Position [X Y Z W P Q R]\\n')\n",
    "        ftrain.write('\\n')\n",
    "        for seq in train_seqs:\n",
    "            im_regx = os.path.join(origin_dir, dataset,'seq-{}'.format(seq), '*.color.png')\n",
    "            im_files = glob.glob(im_regx)\n",
    "            for im_file in im_files:\n",
    "                frame = 'seq-{}/{}'.format(seq, im_file.split('/')[-1])\n",
    "                pose_txt = im_file.replace('color.png', 'pose.txt')\n",
    "                pose = np.loadtxt(pose_txt)\n",
    "                R = pose[0:3, 0:3]\n",
    "                q = mat2quat(R.T) # IMPORTANT!\n",
    "                c = pose[0:3, 3] \n",
    "                cur = [frame]\n",
    "                cur += [\"{:.8f}\".format(i) for i in c]\n",
    "                cur += [\"{:.8f}\".format(i) for i in q]\n",
    "                ftrain.write(' '.join(cur)+'\\n')\n",
    "                train_num += 1\n",
    "    print('Save {}, training frame number: {}'.format(ftrain.name, train_num))\n",
    "    \n",
    "    test_seqs = split[dataset][1]\n",
    "    with open(os.path.join(target_dir, dataset, test_txt), 'w') as ftest:\n",
    "        ftest.write('7Scenes {} Dataset -- Test Split\\n'.format(dataset))\n",
    "        ftest.write('ImageFile, Camera Position [X Y Z W P Q R]\\n')\n",
    "        ftest.write('\\n')\n",
    "        for seq in test_seqs:\n",
    "            im_regx = os.path.join(origin_dir, dataset,'seq-{}'.format(seq), '*.color.png')\n",
    "            im_files = glob.glob(im_regx)\n",
    "            for im_file in im_files:\n",
    "                frame = 'seq-{}/{}'.format(seq, im_file.split('/')[-1])            \n",
    "                pose_txt = im_file.replace('color.png', 'pose.txt')\n",
    "                pose = np.loadtxt(pose_txt)\n",
    "                R = pose[0:3, 0:3]\n",
    "                q = mat2quat(R.T)\n",
    "                c = pose[0:3, 3]\n",
    "                cur = [frame]\n",
    "                cur += [\"{:.8f}\".format(i) for i in c]\n",
    "                cur += [\"{:.8f}\".format(i) for i in q]\n",
    "                ftest.write(' '.join(cur)+'\\n')\n",
    "                test_num += 1\n",
    "    print('Save {}, testing frame number: {}\\n'.format(ftest.name, test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split validation set from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>chess {'seq-01': 1000, 'seq-02': 1000, 'seq-04': 1000, 'seq-06': 1000}\n",
      "Val step 4 Train: 3004 Val: 996\n",
      ">>>>heads {'seq-02': 1000}\n",
      "Val step 4 Train: 751 Val: 249\n",
      ">>>>fire {'seq-01': 1000, 'seq-02': 1000}\n",
      "Val step 4 Train: 1502 Val: 498\n",
      ">>>>office {'seq-01': 1000, 'seq-03': 1000, 'seq-04': 1000, 'seq-05': 1000, 'seq-08': 1000, 'seq-10': 1000}\n",
      "Val step 4 Train: 4506 Val: 1494\n",
      ">>>>pumpkin {'seq-02': 1000, 'seq-03': 1000, 'seq-06': 1000, 'seq-08': 1000}\n",
      "Val step 4 Train: 3004 Val: 996\n",
      ">>>>redkitchen {'seq-01': 1000, 'seq-02': 1000, 'seq-05': 1000, 'seq-07': 1000, 'seq-08': 1000, 'seq-11': 1000, 'seq-13': 1000}\n",
      "Val step 4 Train: 5257 Val: 1743\n",
      ">>>>stairs {'seq-02': 500, 'seq-03': 500, 'seq-05': 500, 'seq-06': 500}\n",
      "Val step 4 Train: 1504 Val: 496\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "random.seed(0)\n",
    "base_dir = '../data/7Scenes_256/'\n",
    "datasets = ['chess', 'heads', 'fire', 'office', 'pumpkin', 'redkitchen', 'stairs']\n",
    "val_step = 4\n",
    "\n",
    "for dataset in datasets:\n",
    "    counts = {}\n",
    "    seq_lines = {}\n",
    "    with open(os.path.join(base_dir, dataset, 'dataset_train.txt'), 'r') as f:\n",
    "        lines = sorted(f.readlines())\n",
    "        for line in lines:\n",
    "            if not line.startswith('seq'):\n",
    "                continue\n",
    "            seq = line.split()[0].split('/')[0]\n",
    "            if seq not in counts:\n",
    "                counts[seq] = 0\n",
    "                seq_lines[seq] = []\n",
    "            counts[seq] += 1\n",
    "            seq_lines[seq].append(line)\n",
    "    print('>>>>{} {}'.format(dataset,counts))\n",
    "\n",
    "    val_lines = []\n",
    "    train_lines = []\n",
    "    for seq in counts:\n",
    "        num = counts[seq]\n",
    "        for i,line in enumerate(seq_lines[seq]):\n",
    "            if i % val_step == 0 and i > 0:\n",
    "                val_lines.append(line)\n",
    "            else:\n",
    "                train_lines.append(line)\n",
    "    print('Val step {} Train: {} Val: {}'.format(val_step, len(train_lines), len(val_lines)))\n",
    "\n",
    "    train = open(os.path.join(base_dir, dataset, 'train.exp2.txt'), 'w')\n",
    "    train.writelines(train_lines)\n",
    "    val = open(os.path.join(base_dir, dataset, 'val.exp2.txt'), 'w')\n",
    "    val.writelines(val_lines)\n",
    "    train.close()\n",
    "    val.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
